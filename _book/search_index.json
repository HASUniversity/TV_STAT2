[
["index.html", "Stat2: General linear model Voorwoord", " Stat2: General linear model Mark Smits 2019-10-04 Voorwoord Bij STAT1 hebben jullie geleerd wat statistisch toetsen inhoudt, en dit in de praktijk gebracht a.d.v. de t-toetsen. Mogelijk heb je ook in je Bioxperienceproject al een statistische toets uitgevoerd. Dit jaar gaan jullie aan de slag met het jaarproject. Hiervoor moeten jullie zelf een experiment ontwerpen, uitvoeren en de verkregen data verwerken. Dit blok beginnen we met twee lessen over experimental design: het ontwerpen van experimenten. Door je experiment slim te ontwerpen kan je storende factoren buitensluiten, en heb je daardoor grotere kans dat je je onderzoeksvraag goed kan beantwoorden. Dit blok breiden we de toetsen uit met de General Linear Models (GLMs). GLM is waarschijnlijk de meeste gebruikte statistische toets binnen de biologie. Deze toets is heel flexibel, waardoor het toepasbaar is op veel soorten experimenten. "],
["opzet.html", "Opzet", " Opzet Dit blok is op dezelfde manier opgezet als STAT1: zes weken lang een werkcollege van 1,5 uur en in week 7 een hoorcollege als afsluiting. We gaan weer het boek The Analysis of Biological Data gebruiken. Jullie worden geacht vooraf de aangegeven hoofdstukken gelezen te hebben! Nieuw is dat je de opgaven voorafgaande aan het volgende werkcollege ingeleverd moet hebben op blackboard. Dus vanaf les twee. Daar hoor je de eerste les meer over. Veel plezier met statistiek! "],
["les-1-experimental-design.html", "Les 1: Experimental design", " Les 1: Experimental design Lees Chapter 14 (Designing experiments): 14.1 Why do experiments 14.2 Lessons from clinical trials 14.3 How to reduce bias? 14.4 How to reduce the influence of sampling error Opdracht 1 Maak de volgende practical problems uit het boek: 1, 3, 5, 6, 7, 8, 10, 14 "],
["les-2-experimental-design-vervolg.html", "Les 2: Experimental design, vervolg", " Les 2: Experimental design, vervolg Lees Chapter 14 (Designing experiments): 14.5 Experiments with more than one factor 14.6 Choosing a sample size "],
["power-berekenen-in-r.html", "Power berekenen in R", " Power berekenen in R De power van een toets is de waarschijnlijkheid dat, als er een verschil is, deze ook wordt aangetoond (dus een p-waarde onder de drempelwaarde ). Wanneer je een inschatting hebt van de variantie en het minimale verschil wat je wilt kunnen aantonen, dan kan je voor een gekozen aantal herhalingen berekenen wat de power is. Andersom kan ook: je wilt een minimale power hebben (meestal minstens 0,8), dan kan je berekenen hoeveel herhalingen je daar minimaal voor nodig hebt. In R heb je voor verschillende statistische toetsen een power-functie. Voor de t-toets is dat power.t.test(). De belangrijkste argumenten die je mee kan geven aan deze functie zijn: n = aantal herhalingen per groep delta = het absolute verschil dat je minimaal wilt aantonen sd = standaarddeviatie Stel je wilt weten hoeveel herhalingen je nodig hebt om met een power van 0,8 minimaal een verschil van 1 wilt aantonen in de groei van planten tussen twee behandelingen. De geschatte standaarddeviatie is 0.7. power.t.test(delta=1, sd=0.7, power=0.8) ## ## Two-sample t test power calculation ## ## n = 8.764711 ## delta = 1 ## sd = 0.7 ## sig.level = 0.05 ## power = 0.8 ## alternative = two.sided ## ## NOTE: n is number in *each* group Stel, nu blijk je maar 6 herhalingen kwijt te kunnen in de proef, en je wilt weten wat dán de power wordt: power.t.test(delta=1, sd=0.7, n=6) ## ## Two-sample t test power calculation ## ## n = 6 ## delta = 1 ## sd = 0.7 ## sig.level = 0.05 ## power = 0.6077267 ## alternative = two.sided ## ## NOTE: n is number in *each* group Heb je een gepaarde of een eensteekproef-t-toets, dan moet je dan aangeven met het argument type=&quot;paired&quot; of type=&quot;one.sample&quot;. Opdracht 2 Maak de volgende practical problems uit het boek: 4, 9, 13, 15, 16 "],
["les-3-general-linear-models.html", "Les 3: General Linear Models", " Les 3: General Linear Models Het idee achter de GLM is dat je de variatie in de data beschrijft met een model. Van Biocalculus 1 en 2 weet je dat een model bestaat uit variabelen en parameterwaarden. Ter illustratie een model voor een rechte lijn: \\(y=2x+3\\) In bovenstaand model zijn x en y variabelen, 2 en 3 zijn parameterwaarden. De variabele y is de responsvariabele en x is de verklarende variabele. Stel, je verwacht een lineair verband, maar je weet niet precies hoe die loopt. Je wilt bijvoorbeeld de hoeveelheid zetmeel meten in een oplossing (wat jullie in jaar 1 hebben gedaan). Je weet dat er een lineair verband is tussen de concentratie en absorptie van een bepaalde golflengte. Door het maken van een ijklijn kun je dat verband schatten. Opdracht 3 IJklijn: Zoek de ijklijndata op van de zetmeelproef (of kijk op Blackboard). Maak in R een grafiek Schat visueel hoe de ijklijn moet lopen, en schrijf het model ervan op. "],
["statistisch-schatten.html", "Statistisch schatten", " Statistisch schatten Het schatten van de parameterwaarden is wel te doen als je data heel netjes het model volgt. Maar meestal heb je te maken met aardig wat extra variatie. Doel is om de parameterwaarden zo te kiezen dat de variantie minimaal is. Misschien herinner je nog de term variantie uit jaar 1. Variantie is de gemiddelde kwadraatafstand tot het gemiddelde. Minimaliseren van de variantie wordt dan Ordinary Least Squares genoemd (Square verwijst naar kwadraat), afgekort OLS. Opdracht 4 OLS Ga naar de volgende website. vink Show OLS fit aan. Noteer de sum of squares errors (SSE) voor een horizontale lijn door 0. Zoek uit bij welke waarde van b (terwijl a=0) de SSE minimaal is. Wat stelt deze waarde van b voor? Hoe groot is SSE als je de waardes voor a en b optimaliseert (de rode lijn valt dan samen met de zwarte regressielijn)? "],
["f-toets.html", "F-toets", " F-toets In jaar 1 zijn jullie de t-toets tegengekomen. Hiermee test je (in het geval van een onafhankelijke t-toets) of de gemiddelden van twee groepen significant van elkaar verschillen. Met andere woorden: Hoe waarschijnlijk is het dat je een minstens zo groot verschil krijgt in de steekproefgemiddelden, terwijl er in werkelijkheid geen verschil is (dus de kansverdeling onder de H0). Is die waarschijnlijkheid (de p-waarde) minder dan de drempelwaarde (\\(\\alpha\\), meestal 0,05), dan wordt de H0 verworpen en zeggen we dat het verschil significant is. Wat je (of de computer) doet is een kansverdeling maken van de mogelijke verschillen in gemiddelden. Begin twintigste eeuw heeft Ronald Fisher (zie wikipedia) een alternatieve manier ontwikkeld op basis van verklaarde variantie: de F-toets: \\[F=\\frac{MS_{verklaard}}{MS_{rest}}\\] MS staat voor de Mean Squares, oftewel de gemiddelde kwadraatafstand. Deze manier van toetsen wordt variantieanalyse genoemd, of op zijn Engels Analysis of Variance: ANOVA. Als voorbeeld de data uit de vorige oefening. De totale variantie in de data vind je door een horizontale lijn (dus a=0) door het gemiddelde te trekken (dus b zo kiezen dat SSE minimaal is). De gemiddelde kwadraatafstand wordt dan de gevonden SSE gedeeld door 2 (het aantal waarnemingen - 1). Dat is MStotaal. Als je nu a en b zo kiest dat de SSE geminimaliseerd wordt, hou je restvariantie over. Deel dit door 29 en je hebt MSrest. De verklaarde variantie is MStotaal - MSrest. Gelukkig hoef je niet zelf te goochelen met deze varianties, daar hebben we R voor. Wat je wel moet onthouden is dat hoe beter de fit van het statistisch model, des te hoger F wordt. Met wat extra gegoochel met statistisch formules kan je aantonen dat de kansverdeling van F dezelfde is als de kansverdeling van t2. De berekende waarde voor F (via bovenstaande formule) geeft precies dezelfde uitkomst als de berekende waarde voor t. Kijk maar eens naar onderstaande figuur en de bijbehorende toetsen. t.test(df$lengte~df$groep, var.equal=TRUE) ## ## Two Sample t-test ## ## data: df$lengte by df$groep ## t = -7.1998, df = 18, p-value = 1.063e-06 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -9.529953 -5.224566 ## sample estimates: ## mean in group a mean in group b ## 12.07949 19.45674 summary(lm(df$lengte~df$groep)) ## ## Call: ## lm(formula = df$lengte ~ df$groep) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.3835 -1.6107 0.1688 1.2992 4.4270 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 12.0795 0.7245 16.67 2.17e-12 *** ## df$groepb 7.3773 1.0246 7.20 1.06e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.291 on 18 degrees of freedom ## Multiple R-squared: 0.7423, Adjusted R-squared: 0.7279 ## F-statistic: 51.84 on 1 and 18 DF, p-value: 1.063e-06 Vergelijk je de p-waardes, dan zie je dat ze precies gelijk zijn. En de F-waarde is het kwadraat van de t-waarde (ga zelf na). Waarom heb je dan toch de t-toets moeten leren? Twee redenen: Met een t-toets kan je ook eenzijdig testen (H1: a&lt;b) Bij een t-toets heb je de keuze om wel of niet de aanname te maken dat de variantie gelijk is voor beide groepen. Bij ANOVA maak je altijd die aanname! "],
["glm-in-r.html", "GLM in R", " GLM in R De functie voor de GLM in R is lm(r~v), waarbij r de responsvariabele is en v de verklarende variabele. Wanneer v een interval/ratio-variabele is, dan voert de lm een regressie uit. Wanneer v een nominale variabele is dan verdeelt de lm de data in groepen (zoals in bovenstaande figuur). De output van lm bekijk je met de functie summary(). Hoe ziet dan een mogelijk script uit? library(readxl) df &lt;- read_excel(&quot;data.xlsx&quot;) fit &lt;- lm(df$r~df$v) summary(fit) De stappen uitgelegd: Library readxl activeren om data uit Excel te kunnen lezen. Data importeren uit bijv. Excel. GLM uitvoeren en opslaan als object met de naam fit. De samenvatting van de GLM bekijken. In de volgende hoofdstukken gaan we stap voor stap de GLM uitvoeren, te beginnen met de lineaire regressie. "],
["les-4-lineaire-regressie.html", "Les 4: Lineaire regressie", " Les 4: Lineaire regressie Lees Chapter 17 (Regression): 17.1 Linear regression 17.2 Confidence in predictions 17.3 Testing hypotheses about a slope 17.4 Assumptions of regression 17.5 Assumptions of regression "],
["lineaire-regressie-in-r.html", "Lineaire regressie in R", " Lineaire regressie in R Zoals in de vorige les al genoemd voer je een lineaire regressie uit met de functie lm(). Als voorbeeld de data van de ijklijn van het zetmeelpracticum uit jaar 1: Tabel 1: ijklijn zetmeelproef absorptie concentratie 0.000 0.000 0.030 0.125 0.060 0.250 0.176 0.500 0.249 0.750 0.285 1.000 data importeren Als de data in een Excelbestand staat, importeer je die met de functie read_excel uit de package readxl. Bijv.: library(readxl) ijklijn &lt;- read_excel(&quot;ijklijn.xlsx&quot;) Figuur maken Het is een goede gewoonte om de data eerst in een figuur weer te geven. Dan zie je in één oogopslag of het wel zin heeft de data te gebruiken voor je ijklijn: library(tidyverse) ijklijn %&gt;% ggplot(aes(absorptie, concentratie)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se=FALSE) + theme_classic() Met de regel geom_smooth(method=&quot;lm&quot;, se=FALSE) voeg je de regressielijn al toe. method=&quot;lm&quot; geeft aan dat de lijn bepaald wordt via de functie lm(), dus het GLM. Variantieanalyse uitvoeren Maar wil je details van de uitgevoerde GLM bekijken, moet je alsnog de functie lm() uitvoeren: fit &lt;- lm(ijklijn$concentratie~ijklijn$absorptie) summary(fit) ## ## Call: ## lm(formula = ijklijn$concentratie ~ ijklijn$absorptie) ## ## Residuals: ## 1 2 3 4 5 6 ## -0.01456 0.01528 0.04512 -0.07284 -0.05440 0.08141 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.01456 0.04238 0.344 0.748467 ## ijklijn$absorptie 3.17205 0.24555 12.918 0.000207 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.0659 on 4 degrees of freedom ## Multiple R-squared: 0.9766, Adjusted R-squared: 0.9707 ## F-statistic: 166.9 on 1 and 4 DF, p-value: 0.0002071 Je krijgt dan flink wat output. In volgorde: Call: Het GLM dat je hebt uitgevoerd Residuals: De afwijkingen t.o.v. de ijklijn Coefficients: de parameterwaarden van het regressiemodel. intercept is het snijpunt met de y-as (b in de functie \\(y=ax+b\\)). ijklijn$absorptie is de richtingscoëfficient (dus a in de functie \\(y=ax+b\\)). Estimate is de geschatte parameterwaarde. Std. Error is de standaardfout van de geschatte parameterwaarde. t value is de t-waarde van de geschatte parameterwaarde (onder de H0 dat de parameterwaarde 0 is). Pr(&gt;|t|) is de p-waarde van de tweezijdig tweezijdig uitgevoerde t-toets Signif. codes: de betekenis van de sterretjes (in welke klasse de p-waarde valt). Residual standard error: de geschatte standaarddeviatie van de residuën (het gemiddelde is altijd 0). Multiple R-squared: de R2, oftwel de fractie verklaarde variantie (hoe dichter bij 1 des te beter de fit). Adjusted R-squared: de R2, gecorrigeerd voor de complexiteit van je model. F-statistic: De berekende F-waarde. p-value: de p-waarde die volgt uit de F-toets. Voor meer details, zie de volgende link "],
["regressiemodel-gebruiken-voor-voorspellingen.html", "Regressiemodel gebruiken voor voorspellingen", " Regressiemodel gebruiken voor voorspellingen Vaak voer je een regressie uit om een rekenmodel te maken. Een voorbeeld is de ijklijn van hiervoor. Zo’n ijklijn hebben jullie vorig jaar gebruikt om gevonden absorptiewaarden uit de zetmeeltest om te zetten naar de geschatte zetmeelconcentratie. De omslachtige manier is om uit R de parameterwaarden van de regressie-analyse te halen, in Excel een functie te maken, en hiermee de concentraties te berekenen. Het kan eenvoudiger in R: library(readxl) library(writexl) #Formule maken voor ijklijn fit &lt;- lm(concentratie~absorptie ,data=ijklijn) #Meetdata laden. Zorg dat deze exact dezelfde #variabelenaam heeft als de ijklijn voor absorptie zetmeelproef &lt;- read_excel(&quot;zetmeelproef.xlsx&quot;) #Voorspel de concentratie met de functie predict() zetmeelproef$concentratie &lt;- predict(fit, zetmeelproef) #Data kan je opslaan als csv-bestand (kan je weer lezen in Excel) write_excel(zetmeelproef, &quot;zetmeelproef.csv&quot;) Let op: Zorg ervoor dat je in het lm-model alleen de variabelenamen gebruikt, dataframe roep je op via het argument data=). De variabele met de gemeten waarden moet exact dezelfde naam hebben als die van het lm-model. Wil je van een enkele waarde de voorspelling hebben, moet het toch aangeboden worden als een dataframe in de functie predict: bijv. predict(fit, data.frame(absorptie=1.5)). "],
["oefenen-met-data.html", "Oefenen met data", " Oefenen met data Opdracht 5 Er wordt verondersteld dat de gewichtstoename van zeugen tijdens de dracht een voorspellende waarde hebben voor het geboortegewicht van de biggen. Dat is onderzocht bij 10 zeugen. Download de file zeugen.xslx van blackboard Maak een grafiek met gewichtstoename_zeug op de x-as en geboortegewicht op de y-as Voor een lineaire regressie uit, en zoek uit wat de R2 en de p-waarde is. Voorspel wat het geboortegewicht is van de biggen indien de zeug tijdens de dracht 15 kg toeneemt. "],
["opgaven-uit-het-boek.html", "Opgaven uit het boek", " Opgaven uit het boek Opdracht 6 Maak de volgende practical problems uit het boek: 1*, 2*, 3*, 4, 5, 6*, 7, 8, 9, 12, 14, 16, 17* *Niet met de hand uitrekenen, gebruik lm() en de output er van in R "],
["les-5-one-way-anova.html", "Les 5: One-way ANOVA", " Les 5: One-way ANOVA Lees Chapter 15 (Comparing means of more than two groups): Met een One-way ANOVA kan je, i.t.t. de onafhankelijke t-toets, meer dan twee groepen met elkaar vergelijken. Je hebt dan één verklarende variabele van nominaal of ordinaal niveau, verdeeld in drie of meer groepen. Je kan dat testen of de groepen van elkaar verschillen. Wil je weten welke groepen onderling van elkaar verschillen, dan doe je dat met een posthoctoets. "],
["variantieanalyse.html", "Variantieanalyse", " Variantieanalyse Men doet onderzoek naar de melksnelheid van drie verschillende rassen koeien (HF, MRY en RHF) waarbij de melksnelheid in kg/min is gemeten bij een aantal koeien van deze rassen, zie hieronder: Melkgift is de responsvariabele en ras de verklarende variabele. Nu is de vraag of de rassen van elkaar verschillen in melkgift. Uitgedrukt in hypotheses: H0: gemiddelde melkgift is gelijk voor de drie rassen H1: gemiddelden melkgift zijn niet allemaal gelijk voor de drie rassen Onder de H0 kan de data beschreven worden als één populatie met gemiddelde is 3.04 kg/min. Onder de H1 heeft ieder ras een eigen gemiddelde. We kunnen in de grafiek al zien dat ras MRY nogal afwijkt van de andere twee. Met een ANOVA kunnen we berekenen hoe waarschijnlijk het is dat we een minstens zo afwijkend patroon zien als de H0 wel waar is (dus geen verschil). Hoe voeren we dat uit in R: fit &lt;- lm(Melksnelheid ~ ras, data=koeien) summary(fit) ## ## Call: ## lm(formula = Melksnelheid ~ ras, data = koeien) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.12000 -0.06567 -0.01833 0.06250 0.15800 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.95200 0.04589 64.334 2.67e-13 *** ## rasMRY 0.25800 0.06883 3.748 0.00457 ** ## rasRHF 0.01467 0.07493 0.196 0.84916 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1026 on 9 degrees of freedom ## Multiple R-squared: 0.6427, Adjusted R-squared: 0.5633 ## F-statistic: 8.094 on 2 and 9 DF, p-value: 0.009743 Op de laatste regel van de output staat het resultaat van de F-toets. De p-waarde is 0.0097432. Het is dus heel onwaarschijnlijk dat de H0 waar is, en kunnen die met een gerust hart verwerpen. De F-waarde is 8.0941106. De waarde staat voor de verhouding van verklaarde variantie door het model en overgebleven variantie. Hoe grote de F-waarde, des te beter het model de totale variantie verklaart. We kunnen de totale variantie en overgebleven variantie weergeven in een histogram: De volgende opgave is gebaseerd op een onderzoek, gepubliceerd in the American Society of Animal Science. Het sporenelement silicium (Si) heeft een positieve invloed op de gezondheid van beenderen. In een onderzoek wil men de vraag beantwoord zien of het toevoegen van voedingssupplementen met silicium aan het rantsoen van zogende merries het siliciumgehalte in het bloed van veulens beïnvloedt. In een experiment met 15 zogende merries van hetzelfde ras en ongeveer dezelfde leeftijd probeert men 3 verschillende doses voedingssupplementen met silicium uit. De 15 merries worden via loting toebedeeld aan een specifieke dosis. Na enige tijd meet men het siliciumgehalte in het bloed van de veulens. De resultaten: dosis Si-gehalte (\\(\\mu\\)g/l) 1 129; 137; 129; 134; 139 2 133; 148; 142; 139; 134 3 138; 148; 140; 145; 148 Opdracht 7 Silicium Maak een Excelbestand van bovenstaande data. Verzin een goede structuur Zorg dat het Excelbestand in je projectfolder van RStudio staat Schrijf een script dat de volgende zaken uitvoert: Importeer Excel Test of dosis een effect heeft op siliciumgehalte in het bloed van de veulen m.b.v. een GLM "],
["posthoctoets.html", "Posthoctoets", " Posthoctoets Met een posthoctoets kan je groepen onderling vergelijken. Je voert het uit om te kijken welke groepen onderling significant van elkaar verschillen. Waarom niet gewoon een aantal t-toetsen uitvoeren (je vergelijkt immers telkens twee groepen onderling)? Twee redenen: Ten eerste omdat je op zoek gaat of en waar onderlinge verschillen zitten. En voor al die toetsen bij elkaar wil je de kans op een type-1-fout (ten onrechte H0 verwerpen) op 0,05 houden. Ten tweede omdat je dezelfde data gebruikt om verschillende toetsen uit te voeren. In de loop van de afgelopen eeuw zijn er heel wat verschillende posthoctoetsen ontwikkeld en is het moeilijk door de bomen het bos te zien. We gebruiken een aantal simpele stelregels: Alle groepen onderling vergelijken: Bij ongeveer gelijke groepsgroottes: Tukey HSD. Bij ongelijke groepsgrootte: Bonferroni. Alleen behandelingen ten opzichte van een controlegroep vergelijken: De Dunnet’s posthoctoets. Hoe voeren we die uit (als voorbeeld met de melkgiftdata, waarbij fit het resultaat is van de functie lm())? Tukey HSD: TukeyHSD(aov(fit)) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = fit) ## ## $ras ## diff lwr upr p adj ## MRY-HF 0.25800000 0.06583103 0.45016897 0.0114419 ## RHF-HF 0.01466667 -0.19454041 0.22387374 0.9791490 ## RHF-MRY -0.24333333 -0.46212733 -0.02453934 0.0306896 Resultaat is een lijst van onderlinge vergelijkingen. De bovenste en onderste vergelijking zijn significant (p&lt;0.05). Dus MRY verschilt significant van HF en RHF, maar HF en RHF verschillen onderling niet significant van elkaar. Bonferroni: pairwise.t.test(koeien$Melksnelheid, koeien$ras, p.adj = &quot;bonf&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: koeien$Melksnelheid and koeien$ras ## ## HF MRY ## MRY 0.014 - ## RHF 1.000 0.038 ## ## P value adjustment method: bonferroni Deze test is iets conservatiever (voorzichtiger) dus de p-waardes zijn een fractie hoger. Dunnet’s De Dunnet’s posthoctoets kan je het gemakkelijkst uitvoeren met behulp van de package DescTools. De koeiendataset heeft geen controlegroep, maar als we aannemen dat het ras MRY de controlegroep is, krijg je de volgende code: library(DescTools) DunnettTest(koeien$Melksnelheid, koeien$ras, control = &quot;MRY&quot;) ## ## Dunnett&#39;s test for comparing several treatments with a control : ## 95% family-wise confidence level ## ## $MRY ## diff lwr.ci upr.ci pval ## HF-MRY -0.2580000 -0.4381654 -0.07783462 0.0084 ** ## RHF-MRY -0.2433333 -0.4484606 -0.03820602 0.0229 * ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Opdracht 8 posthoctoets Voer de juiste posthoctoets uit bij voorgaande opgave over silicium. "],
["opgaven-uit-het-boek-1.html", "Opgaven uit het boek", " Opgaven uit het boek Gebruik de functie anova(fit) om de juiste data te vinden voor de opgaven waar aangegeven is om R te gebruiken. Hiermee maak je een ANOVA-tabel die de verschillende varianties weergeeft (SS=sum of squares). Opdracht 9 Maak de volgende practical problems uit het boek: 1*, 2, 3*, 4*, 5*, 6*, 8, 9, 11 *Niet met de hand uitrekenen, gebruik R "],
["les-6-two-way-anova.html", "Les 6: Two-way ANOVA", " Les 6: Two-way ANOVA Lees Chapter 18 (Multiple explanatory variables): Alle paragrafen Opdracht 10 Maak de volgende practical problems uit het boek: 1, 2, 3, 4, 5, 6, 7, 8, 9 "]
]
